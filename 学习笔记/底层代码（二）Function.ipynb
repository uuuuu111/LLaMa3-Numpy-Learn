{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8710571-9bc6-413e-a31a-a570af2ea284",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Function:\n",
    "    def __call__(self, *inputs: Union[np.ndarray, Variable]) -> Union[list[Variable], Variable]:\n",
    "        # 当这个函数被调用的时候，记录这个函数的输入，输出\n",
    "        inputs: list[Variable] = [as_variable(x) for x in inputs]\n",
    "\n",
    "        xs = [x.data for x in inputs] #读取传进来的输入\n",
    "\n",
    "        ys = self.forward(*xs) #计算输出\n",
    "        if not isinstance(ys, tuple):\n",
    "            ys = (ys,) #将输出转换为tuple\n",
    "        outputs = [Variable(as_array(y)) for y in ys]\n",
    "\n",
    "        if Config.enable_backprop:\n",
    "            self.generation = max([x.generation for x in inputs]) #确保函数的generation大于函数所有输入的generation\n",
    "            for output in outputs:\n",
    "                output.set_creator(self) #设置输出变量的creator\n",
    "            self.outputs = [weakref.ref(output) for output in outputs]\n",
    "            # outputs中储存的是对所有output的弱引用，好处是当output不再被其他对象引用时，弱引用可以被\n",
    "            # 垃圾回收机制释放，避免内存泄漏\n",
    "            self.inputs = inputs\n",
    "\n",
    "        return outputs if len(outputs) > 1 else outputs[0]\n",
    "\n",
    "    def forward(self, *xs: np.ndarray) -> tuple[np.ndarray]:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def backward(self, gys: np.ndarray) -> Union[tuple[np.ndarray, ...], np.ndarray]:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec148a73-8a8e-4fb6-86c9-4a6e98fe7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各种函数具体的forward和backward实现，这里只截取了一部分特殊函数\n",
    "# 可以仔细看看backward的实现\n",
    "class Reshape(Function):\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> tuple[np.ndarray]:\n",
    "        self.x_shape = x.shape\n",
    "        y = x.reshape(self.shape)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy: np.ndarray) -> Union[tuple[Variable, ...], Variable]:\n",
    "        return reshape(gy, self.x_shape) #就是reshape回去\n",
    "\n",
    "\n",
    "def reshape(x, shape):\n",
    "    if x.shape == shape:\n",
    "        return as_variable(x)\n",
    "    return Reshape(shape)(x)\n",
    "\n",
    "class Transpose(Function):\n",
    "    def __init__(self, axes=None):\n",
    "        self.axes = axes\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.transpose(self.axes)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        if self.axes is None:\n",
    "            return transpose(gy) \n",
    "\n",
    "        axes_len = len(self.axes)\n",
    "        inv_axes = tuple(np.argsort([ax % axes_len for ax in self.axes]))\n",
    "        return transpose(gy, inv_axes)\n",
    "\n",
    "    # 原来的shape[0, 1, 2, 3]\n",
    "    # 假设axes=[3, 1, 0, 2] axes_len=4\n",
    "    # argsort返回一个储存了下标的数组，下标的顺序使得下标对应的值从小到大排序\n",
    "    # inv_axes=[2, 1, 3, 0] # 再转置后确保梯度与前向传播时的输入数据保持一致。\n",
    "\n",
    "\n",
    "def transpose(x, axes=None):\n",
    "    return Transpose(axes)(x)\n",
    "\n",
    "\n",
    "class BroadcastTo(Function):\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> Union[tuple[np.ndarray, ...], np.ndarray]:\n",
    "        self.x_shape = x.shape\n",
    "        xp = get_array_module(x)\n",
    "        y = xp.broadcast_to(x, self.shape)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy: np.ndarray) -> Union[tuple[Variable, ...], Variable]:\n",
    "        gx = sum_to(gy, self.x_shape) #加回去，把多broadcast出来的大小舍去\n",
    "        return gx\n",
    "\n",
    "\n",
    "def broadcast_to(x, shape):\n",
    "    if x.shape == shape:\n",
    "        return as_variable(x)\n",
    "    return BroadcastTo(shape)(x)\n",
    "\n",
    "\n",
    "class SumTo(Function):\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> Union[tuple[np.ndarray, ...], np.ndarray]:\n",
    "        self.x_shape = x.shape\n",
    "        y = raw_sum_to(x, self.shape)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy: np.ndarray) -> Union[tuple[Variable, ...], Variable]:\n",
    "        gx = broadcast_to(gy, self.x_shape) # 把原来因为加上缺失的维度补上\n",
    "        return gx\n",
    "\n",
    "\n",
    "def sum_to(x, shape):\n",
    "    if x.shape == shape:\n",
    "        return as_variable(x)\n",
    "    return SumTo(shape)(x)\n",
    "\n",
    "\n",
    "class MatMul(Function): #矩阵乘法\n",
    "    def forward(self, x: np.ndarray, W: np.ndarray) -> tuple[np.ndarray]:\n",
    "        if x.ndim <= 2 and W.ndim <= 2:\n",
    "            y = x.dot(W)\n",
    "        else:\n",
    "            y = x @ W\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy: np.ndarray) -> Union[tuple[Variable, ...], Variable]:\n",
    "        x, W = self.inputs\n",
    "        gx = matmul(gy, W.transpose(([i for i in range(W.ndim - 2)] + [-1, -2])))\n",
    "        # 将W最后两个维度交换后和gy相乘\n",
    "        # 按照数学定义，gx=gy·W^T,为什么只交换W的最后两个维度，是因为\n",
    "        gW = matmul(x.transpose(([i for i in range(x.ndim - 2)] + [-1, -2])), gy)\n",
    "        return gx, gW\n",
    "\n",
    "\n",
    "def matmul(x, W):\n",
    "    return MatMul()(x, W)\n",
    "\n",
    "\n",
    "class MeanSquaredError(Function):\n",
    "    def forward(self, x0: np.ndarray, x1: np.ndarray) -> np.ndarray:\n",
    "        diff = x0 - x1\n",
    "        y = (diff ** 2).sum() / len(diff)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy: np.ndarray) -> Union[tuple[Variable, ...], Variable]:\n",
    "        x0, x1 = self.inputs\n",
    "        diff: Variable = x0 - x1\n",
    "        gx0: Variable = gy * diff * (2. / len(diff))\n",
    "        gx1: Variable = -gx0\n",
    "        return gx0, gx1\n",
    "\n",
    "\n",
    "def mean_squared_error(x, y):\n",
    "    return MeanSquaredError()(x, y)\n",
    "\n",
    "\n",
    "class Linear(Function):\n",
    "    def forward(self, x: np.ndarray, W: np.ndarray, b: np.ndarray) -> tuple[np.ndarray]:\n",
    "        y = x.dot(W)\n",
    "        if b is not None:\n",
    "            y += b\n",
    "\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy: np.ndarray) -> Union[tuple[Variable, ...], Variable]:\n",
    "        x, W, b = self.inputs\n",
    "        gb = None if b.data is None else sum_to(gy, b.shape)\n",
    "        gx = matmul(gy, W.transpose(([i for i in range(W.ndim - 2)] + [-1, -2])))\n",
    "        gW = matmul(x.transpose(([i for i in range(x.ndim - 2)] + [-1, -2])), gy)\n",
    "        return gx, gW, gb\n",
    "\n",
    "\n",
    "def linear(x, W, b=None):\n",
    "    return Linear()(x, W, b)\n",
    "\n",
    "\n",
    "class Sigmoid(Function):\n",
    "    def forward(self, x: np.ndarray) -> tuple[np.ndarray]:\n",
    "        # y = 1 / (1 + exp(-x))\n",
    "        xp = get_array_module(x)\n",
    "        y = xp.tanh(x * 0.5) * 0.5 + 0.5\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy: np.ndarray) -> Union[tuple[np.ndarray, ...], np.ndarray]:\n",
    "        y = self.outputs[0]()\n",
    "        gx = gy * y * (1 - y)\n",
    "        return gx\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return Sigmoid()(x)\n",
    "\n",
    "\n",
    "class GetItem(Function):\n",
    "    def __init__(self, slices):\n",
    "        self.slices = slices\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> tuple[np.ndarray]:\n",
    "        y = x[self.slices]\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy: np.ndarray) -> Union[tuple[Variable, ...], Variable]:\n",
    "        x = self.inputs[0]\n",
    "        f = GetItemGrad(self.slices, x.shape)\n",
    "        return f(gy)\n",
    "\n",
    "\n",
    "def get_item(x, slices):\n",
    "    return GetItem(slices)(x)\n",
    "\n",
    "\n",
    "class GetItemGrad(Function):\n",
    "    def __init__(self, slices, in_shape):\n",
    "        self.slices = slices\n",
    "        self.in_shape = in_shape\n",
    "\n",
    "    def forward(self, gy: np.ndarray) -> Union[tuple[np.ndarray, ...], np.ndarray]:\n",
    "        xp = get_array_module(gy)\n",
    "        gx = xp.zeros(self.in_shape)\n",
    "        if xp is np:\n",
    "            np.add.at(gx, self.slices, gy)\n",
    "        else:\n",
    "            xp.scatter_add(gx, self.slices, gy)\n",
    "        return gx\n",
    "\n",
    "    def backward(self, ggx: np.ndarray) -> Union[tuple[Variable, ...], Variable]:\n",
    "        return get_item(ggx, self.slices)\n",
    "\n",
    "\n",
    "class Softmax(Function):\n",
    "    def __init__(self, axis=1):\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> tuple[np.ndarray]:\n",
    "        xp = get_array_module(x)\n",
    "        y = x - x.max(axis=self.axis, keepdims=True)\n",
    "        y = xp.exp(y)\n",
    "        y /= y.sum(axis=self.axis, keepdims=True)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy: np.ndarray) -> Union[tuple[np.ndarray, ...], np.ndarray]:\n",
    "        y = self.outputs[0]()\n",
    "        gx = y * gy\n",
    "        sumdx = gx.sum(axis=self.axis, keepdims=True)\n",
    "        gx -= y * sumdx\n",
    "        return gx\n",
    "\n",
    "\n",
    "def softmax(x, axis=1):\n",
    "    return Softmax(axis=axis)(x)\n",
    "\n",
    "\n",
    "class Cat(Function):\n",
    "    def __init__(self, axis: int = 0):\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, *xs: np.ndarray) -> np.ndarray:\n",
    "        xp = get_array_module(xs[0])\n",
    "        z = xp.concatenate(xs, axis=self.axis)\n",
    "        return z\n",
    "\n",
    "    def backward(self, gy: Variable) -> Union[tuple[Variable, ...], Variable]:\n",
    "        inputs = self.inputs\n",
    "        gx = []\n",
    "        start_idx = 0\n",
    "        for x in inputs:\n",
    "            end_idx = start_idx + x.shape[self.axis]\n",
    "            indices = [slice(None)] * gy.ndim\n",
    "            indices[self.axis] = slice(start_idx, end_idx)\n",
    "            gx.append(gy[tuple(indices)])\n",
    "            start_idx = end_idx\n",
    "\n",
    "        return tuple(gx)\n",
    "\n",
    "\n",
    "def cat(inputs, axis=0):\n",
    "    return Cat(axis=axis)(*inputs)\n",
    "\n",
    "\n",
    "class Clip(Function):\n",
    "    def __init__(self, x_min, x_max):\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> Union[tuple[np.ndarray, ...], np.ndarray]:\n",
    "        xp = get_array_module(x)\n",
    "        y = xp.clip(x, self.x_min, self.x_max)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy: np.ndarray) -> Union[tuple[np.ndarray, ...], np.ndarray]:\n",
    "        x = self.inputs[0]\n",
    "        mask = (x.data >= self.x_min) * (x.data <= self.x_max)\n",
    "        gx = gy * mask\n",
    "        return gx\n",
    "\n",
    "\n",
    "def clip(x, x_min, x_max):\n",
    "    return Clip(x_min, x_max)(x)\n",
    "\n",
    "\n",
    "def softmax_cross_entropy_simple(x, t):\n",
    "    x, t = as_variable(x), as_variable(t)\n",
    "    N = x.shape[0]\n",
    "\n",
    "    p = softmax(x)\n",
    "    p = clip(p, 1e-15, 1.0)\n",
    "    log_p = log(p)\n",
    "    tlog_p = log_p[np.arange(N), t.data]\n",
    "    y = -1 * sum(tlog_p) / N\n",
    "    return y\n",
    "\n",
    "\n",
    "def accuracy(y, t):\n",
    "    y, t = as_variable(y), as_variable(t)\n",
    "\n",
    "    pred = y.data.argmax(axis=1).reshape(t.shape)\n",
    "    result = (pred == t.data)\n",
    "    acc = result.mean()\n",
    "\n",
    "    return Variable(as_array(acc))\n",
    "\n",
    "\n",
    "def dropout(x, dropout_ratio=0.5):\n",
    "    x = as_variable(x)\n",
    "\n",
    "    if Config.train:\n",
    "        xp = get_array_module(x)\n",
    "        mask = xp.random.rand(*x.shape) > dropout_ratio\n",
    "        scale = xp.array(1.0 - dropout_ratio).astype(x.dtype)\n",
    "        y = x * mask / scale\n",
    "        return y\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "class Stack(Function):\n",
    "    def __init__(self, axis: int = 0):\n",
    "        self.axis = axis\n",
    "\n",
    "    def forward(self, *xs: np.ndarray) -> Union[tuple[np.ndarray, ...], np.ndarray]:\n",
    "        xp = get_array_module(xs[0])\n",
    "        self.x_shape = xs[0].shape\n",
    "        self.x_num = len(xs)\n",
    "        y = xp.stack(xs, axis=self.axis)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy: np.ndarray) -> Union[tuple[np.ndarray, ...], np.ndarray]:\n",
    "        gx = []\n",
    "        for i in range(self.x_num):\n",
    "            indices = [slice(None)] * gy.ndim\n",
    "            indices[self.axis] = slice(i, i + 1)\n",
    "            gx.append(gy[tuple(indices)].reshape(self.x_shape))\n",
    "        return tuple(gx)\n",
    "\n",
    "\n",
    "def stack(inputs, axis=0):\n",
    "    return Stack(axis=axis)(*inputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
